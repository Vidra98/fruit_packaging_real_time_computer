{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2023-06-26 18:44:37,563 - utils - NumExpr defaulting to 8 threads.\n",
      "INFO - 2023-06-26 18:44:38,145 - base_toolkit - Could not load plugin 'qt' from 'pyface.ui.qt.init'\n",
      "INFO - 2023-06-26 18:44:38,146 - base_toolkit - No pyface.toolkits plugin could be loaded for qt\n",
      "INFO - 2023-06-26 18:44:38,147 - base_toolkit - Could not load traitsui.toolkits plugin 'qt' from 'traitsui.qt4'\n",
      "INFO - 2023-06-26 18:44:38,148 - base_toolkit - Could not load traitsui.toolkits plugin 'wx' from 'traitsui.wx'\n",
      "INFO - 2023-06-26 18:44:38,195 - base_toolkit - Could not load plugin 'qt4' from 'pyface.ui.qt.init'\n",
      "INFO - 2023-06-26 18:44:38,196 - base_toolkit - No pyface.toolkits plugin could be loaded for qt4\n",
      "INFO - 2023-06-26 18:44:38,196 - base_toolkit - Could not load traitsui.toolkits plugin 'qt4' from 'traitsui.qt4'\n"
     ]
    }
   ],
   "source": [
    "from PyLQR.sim import KDLRobot\n",
    "from PyLQR.system import PosOrnPlannerSys, PosOrnKeypoint\n",
    "from PyLQR.solver import BatchILQRCP, BatchILQR, ILQRRecursive\n",
    "from PyLQR.utils import primitives, PythonCallbackMessage\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from scipy.spatial.transform import Rotation \n",
    "\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "\n",
    "from utils.camera_utils import RealCamera, RealCameraROS\n",
    "from utils.transform_utils import *\n",
    "from utils.iLQR_wrapper import iLQR\n",
    "from utils.visualisation_utils import depth2pc\n",
    "from utils.ROS_utils import generate_grasps_client, format_pointcloud_msg, run_action, get_camera_pose, gridRegistrator\n",
    "\n",
    "import argparse\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "import time\n",
    "\n",
    "from contact_grasp.srv import contactGraspnetPointcloud2, contactGraspnetPointcloud2Response\n",
    "\n",
    "import json\n",
    "import rospy\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from sensor_msgs import point_cloud2\n",
    "from sensor_msgs.msg import PointField, CameraInfo, Image, PointCloud2\n",
    "from std_msgs.msg import Header\n",
    "from geometry_msgs.msg import PoseArray, Pose\n",
    "import message_filters\n",
    "\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera topic found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] [1687797884.088024]: No controllers are running\n"
     ]
    }
   ],
   "source": [
    "bridge = CvBridge()\n",
    "try:\n",
    "    rospy.init_node(\"python_node\",anonymous=True)\n",
    "except:\n",
    "    print(\"rospy already initialized\")\n",
    "\n",
    "# dispose_pos = np.array([dim, 0.66, 0.1])\n",
    "# dispose_orn_wxyz = np.array([0, 1, 0.35, 0])\n",
    "\n",
    "camera_connexion = \"ROS\"\n",
    "if camera_connexion == \"ROS\":\n",
    "    camera = RealCameraROS()\n",
    "    intrinsic, distortion = camera.getIntrinsic()\n",
    "elif camera_connexion == \"pyWrapper\":\n",
    "    camera = RealCamera()\n",
    "    camera.start()\n",
    "    intrinsic, distortion = camera.getIntrinsic()\n",
    "    #retrieve image and depth to initialise camera, otherwise image is very dark\n",
    "    for i in range(15):\n",
    "        rgb, depth_image, depth_scale = camera.get_rgb_depth()\n",
    "else:\n",
    "    raise Exception(\"Please choose a valid camera connexion method: ROS or pyWrapper\")\n",
    "\n",
    "sys.path.append(\"/home/vdrame/catkin_ws/src/py_panda/PyPanda\")\n",
    "from PyPanda import Robot\n",
    "from PyPanda import Utils\n",
    "rbt = Robot(\"panda\", use_gripper=True)\n",
    "current_pose = get_camera_pose(rbt, ee_depth=-0.10340-0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_triangle(dim=0.1, color=[1, 0, 0]):\n",
    "    halfdim=dim/2\n",
    "    points = [\n",
    "        [0, 0, 0],\n",
    "        [-halfdim, -halfdim, dim],\n",
    "        [halfdim, -halfdim, dim],\n",
    "        [halfdim, halfdim, dim],\n",
    "        [-halfdim, halfdim, dim],\n",
    "\n",
    "    ]\n",
    "    lines = [\n",
    "        [0, 1],\n",
    "        [0, 2],\n",
    "        [0, 3],\n",
    "        [0, 4],\n",
    "        [1, 2],\n",
    "        [2, 3],\n",
    "        [3, 4],\n",
    "        [4, 1],\n",
    "\n",
    "    ]\n",
    "    colors = [color for i in range(len(lines))]\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(points),\n",
    "        lines=o3d.utility.Vector2iVector(lines),\n",
    "    )\n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    return line_set\n",
    "\n",
    "ls = draw_triangle()\n",
    "o3d.visualization.draw_geometries([ls])\n",
    "\n",
    "def draw_box(points):\n",
    "    lines = [\n",
    "        [0, 1],\n",
    "        [0, 2],\n",
    "        [1, 3],\n",
    "        [2, 3],\n",
    "        [4, 5],\n",
    "        [4, 6],\n",
    "        [5, 7],\n",
    "        [6, 7],\n",
    "        [0, 4],\n",
    "        [1, 5],\n",
    "        [2, 6],\n",
    "        [3, 7],\n",
    "    ]\n",
    "    colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(points),\n",
    "        lines=o3d.utility.Vector2iVector(lines),\n",
    "    )\n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    return line_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling time: 0.6065032482147217s, Filtering time: 0.12414312362670898s\n",
      "[TriangleMesh with 1134 points and 2240 triangles., LineSet with 8 lines.]\n"
     ]
    }
   ],
   "source": [
    "#load pos and orn from json file\n",
    "with open('config/views_pos.json') as json_file:\n",
    "    views_pos = json.load(json_file)\n",
    "\n",
    "pos_dif = 1000\n",
    "keys = views_pos.keys()\n",
    "angle_range = [-140, 40]\n",
    "pc_fused = []\n",
    "pc_colors_fused = []\n",
    "reference_pose = np.eye(4)\n",
    "plot_coordinate = []\n",
    "# while (not detected or not detected_with_collision):\n",
    "horizon = 30\n",
    "\n",
    "bgr_cv, depth_cv, depth_scale = camera.get_rgb_depth()\n",
    "depth_cv = depth_cv * depth_scale\n",
    "rgb_cv = cv2.cvtColor(bgr_cv, cv2.COLOR_BGR2RGB)\n",
    "pc_fused, pc_colors_fused = depth2pc(depth_cv, intrinsic, rgb_cv)\n",
    "pc_fused, pc_colors_fused = regularize_pc(pc_fused, pc_colors_fused, \n",
    "                                            downsampling_method=\"voxel\", voxel_size=0.005,\n",
    "                                            outlier_filtering_method=\"radius\", radius_param_arg=[25, 0.015])\n",
    "\n",
    "pc_fused = current_pose @ np.concatenate((pc_fused, np.ones((pc_fused.shape[0], 1))), axis=1).T\n",
    "pc_fused = pc_fused.T[:, :3]\n",
    "coordinate = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1).transform(current_pose)\n",
    "coordinate_line = draw_triangle(color=[1,0,0]).transform(current_pose)\n",
    "\n",
    "# coordinate_line.transform(current_pose)\n",
    "# coordinate.transform(current_pose)\n",
    "plot_coordinate.append(coordinate)\n",
    "plot_coordinate.append(coordinate_line)\n",
    "\n",
    "print(plot_coordinate)\n",
    "pc_o3d = o3d.geometry.PointCloud()\n",
    "pc_o3d.points = o3d.utility.Vector3dVector(pc_fused)\n",
    "pc_o3d.colors = o3d.utility.Vector3dVector(pc_colors_fused[:, [2,1,0]]/255)\n",
    "coordinate = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1)\n",
    "# coordinate.translate([0,0 , 0.4])\n",
    "pc_o3d.transform(reference_pose)\n",
    "to_draw = plot_coordinate.copy()\n",
    "to_draw.append(pc_o3d)\n",
    "o3d.visualization.draw_geometries(to_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "# from utils.segmentation import YOLOSegmentation\n",
    "import cv2\n",
    "import numpy as np\n",
    "import rospy\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from sensor_msgs.msg import Image\n",
    "from contact_grasp.srv import segmentationSrv, segmentationSrvResponse\n",
    "from utils.camera_utils import RealCamera, RealCameraROS\n",
    "\n",
    "bridge = CvBridge()\n",
    "try:\n",
    "    rospy.init_node(\"python_node\",anonymous=True)\n",
    "except:\n",
    "    print(\"rospy already initialized\")\n",
    "\n",
    "bgr = cv2.cvtColor(rgb_cv, cv2.COLOR_RGB2BGR)\n",
    "#load cv image\n",
    "# img = cv2.imread(\"/home/vdrame/bgr.png\")\n",
    "\n",
    "#convert to ros image\n",
    "ros_img = bridge.cv2_to_imgmsg(bgr, encoding=\"bgr8\")\n",
    "\n",
    "#call service\n",
    "# rospy.wait_for_service(\"segmentation\")\n",
    "\n",
    "try:\n",
    "    segmentation = rospy.ServiceProxy(\"segmentation\", segmentationSrv)\n",
    "    resp = segmentation(ros_img)\n",
    "except rospy.ServiceException as e:\n",
    "    print(e)\n",
    "\n",
    "#convert to cv image\n",
    "segmap = bridge.imgmsg_to_cv2(resp.image, desired_encoding=\"passthrough\")\n",
    "print(np.unique(segmap))\n",
    "#show image\n",
    "cv2.imshow(\"segmented image\", segmap)\n",
    "cv2.imshow(\"rgb\", rgb_cv)\n",
    "key=cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "def get_ROI_box(pc, pc_colors, depth, rgb, segmap, intrinsic, extrinsic, border_size = 0.05):\n",
    "\n",
    "    pc_seg, pc_colors_seg = depth2pc(depth, intrinsic, rgb, segmap=segmap)\n",
    "    pc_seg = extrinsic @ np.concatenate((pc_seg, np.ones((pc_seg.shape[0], 1))), axis=1).T\n",
    "    pc_seg = pc_seg.T[:, :3]    \n",
    "    \n",
    "    min_bound = np.min(pc_seg, axis=0) - [border_size, border_size, 0]\n",
    "    max_bound = np.max(pc_seg, axis=0) + [border_size, border_size, 0]\n",
    "\n",
    "    bounding_point = np.array([[min_bound[0], min_bound[1], min_bound[2], 1],\n",
    "                            [min_bound[0], min_bound[1], max_bound[2], 1],\n",
    "                            [min_bound[0], max_bound[1], min_bound[2], 1],\n",
    "                            [min_bound[0], max_bound[1], max_bound[2], 1],\n",
    "                            [max_bound[0], min_bound[1], min_bound[2], 1],\n",
    "                            [max_bound[0], min_bound[1], max_bound[2], 1],\n",
    "                            [max_bound[0], max_bound[1], min_bound[2], 1],\n",
    "                            [max_bound[0], max_bound[1], max_bound[2], 1]])\n",
    "    #crop point cloud\n",
    "    ROI_mask = np.array((pc[:,0] > min_bound[0]) & (pc[:,0] < max_bound[0]) &\n",
    "                    (pc[:,1] > min_bound[1]) & (pc[:,1] < max_bound[1]) &\n",
    "                    (pc[:,2] > min_bound[2]) & (pc[:,2] < max_bound[2]))\n",
    "\n",
    "    pc_ROI = pc[ROI_mask]\n",
    "    pc_colors_ROI = pc_colors[ROI_mask]\n",
    "\n",
    "    return pc_ROI, pc_colors_ROI, bounding_point\n",
    "\n",
    "def project_pc(pc, pc_colors, intrinsic, extrinsic, image_size=(720, 1280)):\n",
    "    pc = np.concatenate((pc, np.ones((pc.shape[0], 1))), axis=1)\n",
    "\n",
    "    T = np.eye(4)\n",
    "    #invert transformation\n",
    "    T[:3, 3] = -extrinsic[:3, :3].T @ extrinsic[:3, 3]\n",
    "    T[:3, :3] = extrinsic[:3, :3].T\n",
    "    #apply transformation\n",
    "                    \n",
    "    pc = T @ pc.T\n",
    "    uv = intrinsic @ pc[:3, :]\n",
    "    uv = uv / uv[2, :]\n",
    "    uv = uv[:2, :].T\n",
    "    uv = np.round(uv).astype(np.int32)\n",
    "\n",
    "    #select point in image\n",
    "    mask = (uv[:, 0] >= 0) & (uv[:, 0] < image_size[1]) & (uv[:, 1] >= 0) & (uv[:, 1] < image_size[0])\n",
    "    image = np.zeros((image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "\n",
    "    #draw points on image\n",
    "    image[uv[mask, 1], uv[mask, 0]] = pc_colors[mask][:, [0, 1, 2]]\n",
    "\n",
    "    #draw circle on image\n",
    "    for i in range(uv.shape[0]):\n",
    "        if mask[i]:\n",
    "            cv2.circle(image, (uv[i, 0], uv[i, 1]), round(max(image_size)/200), pc_colors[i], -1)\n",
    "\n",
    "    return image\n",
    "\n",
    "def apply_ROI_box_mask(image, bounding_point, intrinsic, extrinsic, image_size=(720, 1280)):\n",
    "    T = np.eye(4)\n",
    "    #invert transformation\n",
    "    T[:3, 3] = -extrinsic[:3, :3].T @ extrinsic[:3, 3]\n",
    "    T[:3, :3] = extrinsic[:3, :3].T\n",
    "\n",
    "    #apply transformation\n",
    "    bounding_point_uv = T @ bounding_point.T\n",
    "    bounding_point_uv = intrinsic @ bounding_point_uv[:3, :]\n",
    "    bounding_point_uv = bounding_point_uv / bounding_point_uv[2, :]\n",
    "    bounding_point_uv = bounding_point_uv[:2, :].T\n",
    "    bounding_point_uv = bounding_point_uv.astype(np.int32)\n",
    "    mask_bounding = (bounding_point_uv[:, 0] >= 0) & (bounding_point_uv[:, 0] < image_size[1]) & (bounding_point_uv[:, 1] >= 0) & (bounding_point_uv[:, 1] < image_size[0])\n",
    "    max_bound = np.max(bounding_point_uv, axis=0)\n",
    "    min_bound = np.min(bounding_point_uv, axis=0)\n",
    "    if min_bound[0] < 0:\n",
    "        min_bound[0] = 0\n",
    "    if min_bound[1] < 0:\n",
    "        min_bound[1] = 0\n",
    "    if max_bound[0] < 0:\n",
    "        max_bound[0] = 0\n",
    "    if max_bound[1] < 0:\n",
    "        max_bound[1] = 0\n",
    "    mask_bounding_ROI = np.ones_like(image)\n",
    "    mask_bounding_ROI[min_bound[1]:max_bound[1], min_bound[0]:max_bound[0]] = 0\n",
    "\n",
    "    image[mask_bounding_ROI.astype(np.bool)] = 255\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pc_ROI, pc_colors_ROI, bounding_point = get_ROI_box(pc_fused, pc_colors_fused, depth_cv, rgb_cv, segmap, intrinsic, current_pose, border_size = 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pos and orn from json file\n",
    "with open('config/views_pos.json') as json_file:\n",
    "    views = json.load(json_file)\n",
    "\n",
    "keys = list(views.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-e1efa47cbd9b>:85: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  image[mask_bounding_ROI.astype(np.bool)] = 255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference_time  1.199622631072998\n",
      "score is : 0.122744140625\n",
      "inference_time  0.0836954116821289\n",
      "score is : 0.14274631076388888\n",
      "inference_time  0.10631799697875977\n",
      "score is : 0.28047960069444444\n",
      "inference_time  0.06861734390258789\n",
      "score is : 0.18974066840277778\n",
      "inference_time  0.1414356231689453\n",
      "score is : 0.095048828125\n",
      "best_score is  0.28047960069444444\n",
      "next view is  view2\n"
     ]
    }
   ],
   "source": [
    "pc_o3d = o3d.geometry.PointCloud()\n",
    "pc_o3d.points = o3d.utility.Vector3dVector(pc_fused)\n",
    "pc_o3d.colors = o3d.utility.Vector3dVector(pc_colors_fused[:, [2,1,0]]/255)\n",
    "\n",
    "bounding_point_o3d = draw_box(bounding_point[:, :3]) # o3d.utility.Vector3dVector(bounding_point[:, :3])\n",
    "bounding_point_o3d.paint_uniform_color([1,0,0])\n",
    "\n",
    "# coordinate.translate([0,0 , 0.4])\n",
    "# pc_o3d.transform(current_pose)\n",
    "to_draw = plot_coordinate.copy()\n",
    "to_draw.append(pc_o3d)\n",
    "to_draw.append(bounding_point_o3d)\n",
    "for view_key in views:\n",
    "    viewTransform = np.eye(4)\n",
    "    viewTransform[0:3, 3] = views[view_key][\"pos\"]\n",
    "    viewTransform[0:3, 0:3] = Rotation.from_quat(np.array(views[view_key][\"orn_wxyz\"])[[1, 2, 3, 0]]).as_matrix()\n",
    "\n",
    "    # coordinate = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1).transform(current_pose)\n",
    "    view_coordinate = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1)\n",
    "    view_coordinate.transform(viewTransform)\n",
    "\n",
    "    view_coordinate_line = draw_triangle(color=[0, 0, 1]).transform(viewTransform)\n",
    "\n",
    "    to_draw.append(view_coordinate)\n",
    "    to_draw.append(view_coordinate_line)\n",
    "\n",
    "o3d.visualization.draw_geometries(to_draw)\n",
    "\n",
    "next_view = None\n",
    "viewBestScore = 0\n",
    "for view_key in views:\n",
    "    viewTransform = np.eye(4)\n",
    "    viewTransform[0:3, 3] = views[view_key][\"pos\"]\n",
    "    viewTransform[0:3, 0:3] = Rotation.from_quat(np.array(views[view_key][\"orn_wxyz\"])[[1, 2, 3, 0]]).as_matrix()\n",
    "\n",
    "    start = time.time()\n",
    "    transform = viewTransform\n",
    "    image = project_pc(pc_fused, pc_colors_fused, intrinsic, transform, image_size=(720, 1280))\n",
    "    image = apply_ROI_box_mask(image, bounding_point, intrinsic, transform, image_size=(720, 1280))\n",
    "    image_1C = np.sum(image, axis=2)\n",
    "    score = np.sum(image_1C == 0)/(image_1C.shape[0] * image_1C.shape[1])\n",
    "    if score > viewBestScore:\n",
    "        viewBestScore = score\n",
    "        next_view = view_key\n",
    "    print(\"inference_time \", time.time() - start)\n",
    "    print(\"score is :\", score)\n",
    "    cv2.imshow(\"image\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "print(\"best_score is \", viewBestScore)\n",
    "print(\"next view is \", next_view)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_o3d = o3d.geometry.PointCloud()\n",
    "pc_o3d.points = o3d.utility.Vector3dVector(pc_ROI)\n",
    "pc_o3d.colors = o3d.utility.Vector3dVector(pc_colors_ROI[:, [2,1,0]]/255)\n",
    "\n",
    "bounding_point_o3d = draw_box(bounding_point[:, :3]) # o3d.utility.Vector3dVector(bounding_point[:, :3])\n",
    "bounding_point_o3d.paint_uniform_color([1,0,0])\n",
    "\n",
    "# coordinate.translate([0,0 , 0.4])\n",
    "# pc_o3d.transform(current_pose)\n",
    "to_draw = plot_coordinate.copy()\n",
    "to_draw.append(pc_o3d)\n",
    "to_draw.append(bounding_point_o3d)\n",
    "\n",
    "viewTransform = np.eye(4)\n",
    "viewTransform[0:3, 3] = views[next_view][\"pos\"]\n",
    "viewTransform[0:3, 0:3] = Rotation.from_quat(np.array(views[next_view][\"orn_wxyz\"])[[1, 2, 3, 0]]).as_matrix()\n",
    "\n",
    "# coordinate = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1).transform(current_pose)\n",
    "view_coordinate = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1)\n",
    "view_coordinate.transform(viewTransform)\n",
    "\n",
    "view_coordinate_line = draw_triangle(color=[0, 0, 1]).transform(viewTransform)\n",
    "\n",
    "to_draw.append(view_coordinate)\n",
    "to_draw.append(view_coordinate_line)\n",
    "\n",
    "o3d.visualization.draw_geometries(to_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
