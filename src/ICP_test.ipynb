{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2023-06-02 17:09:20,492 - topics - topicmanager initialized\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "from utils.camera_utils import RealCamera, RealCameraROS\n",
    "import cv2\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from contact_grasp.srv import segmentationSrv, segmentationSrvResponse\n",
    "from utils.visualisation_utils import depth2pc\n",
    "import rospy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera topic found\n"
     ]
    }
   ],
   "source": [
    "# TODO get image and depth from ros\n",
    "\n",
    "\n",
    "camera_connexion = \"ROS\"\n",
    "if camera_connexion == \"ROS\":\n",
    "    camera = RealCameraROS()\n",
    "    intrinsic, distortion = camera.getIntrinsic()\n",
    "elif camera_connexion == \"pyWrapper\":\n",
    "    camera = RealCamera()\n",
    "    camera.start()\n",
    "    #retrieve image and depth\n",
    "    for i in range(15):\n",
    "        rgb, depth_image, depth_scale = camera.get_rgb_depth()\n",
    "\n",
    "    rgb, depth_image, depth_scale = camera.get_rgb_depth()\n",
    "    intrinsic, distortion = camera.getIntrinsic()\n",
    "else:\n",
    "    raise Exception(\"Please choose a valid camera connexion method: ROS or pyWrapper\")\n",
    "\n",
    "rgb, depth_image, depth_scale = camera.get_rgb_depth()\n",
    "depth = depth_image * depth_scale\n",
    "\n",
    "# TODO segment ROS image\n",
    "\n",
    "#convert to ros image\n",
    "bridge = CvBridge()\n",
    "ros_img = bridge.cv2_to_imgmsg(rgb, encoding=\"rgb8\")\n",
    "try:\n",
    "    segmentation = rospy.ServiceProxy(\"segmentation\", segmentationSrv)\n",
    "    resp = segmentation(ros_img)\n",
    "except rospy.ServiceException as e:\n",
    "    print(e)\n",
    "#convert to cv image\n",
    "segmap = bridge.imgmsg_to_cv2(resp.image, desired_encoding=\"passthrough\")\n",
    "\n",
    "#show on cv2\n",
    "# cv2.imshow(\"rgb\", rgb)\n",
    "# cv2.imshow(\"depth\", depth_image)\n",
    "# cv2.imshow(\"segmap\", segmap)\n",
    "# cv2.waitKey(5000)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "kernel = np.ones((24, 24),np.uint8)\n",
    "erosion = cv2.erode(segmap,kernel,iterations = 1)\n",
    "#TODO get point cloud from depth image\n",
    "\n",
    "\n",
    "pc, pc_colors = depth2pc(depth, intrinsic, rgb, segmap=erosion)\n",
    "mean_pos_pc = np.mean(pc, axis=0)\n",
    "pc_colors[:,[0,2]]=pc_colors[:,[2,0]]\n",
    "#TODO get init translation and rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize pc\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pc)\n",
    "pcd.colors = o3d.utility.Vector3dVector(pc_colors/255)\n",
    "o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial alignment\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.033591e-02, and correspondence_set size of 3571\n",
      "Access transformation to get result.\n",
      "Apply point-to-plane ICP\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.728863e-03, and correspondence_set size of 3571\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.97445937  0.05183872 -0.2184987   0.09271508]\n",
      " [ 0.05124813  0.89598021  0.44112707 -0.3929574 ]\n",
      " [ 0.21863798 -0.44105806  0.87043967 -0.58889541]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def draw_registration_result(source, target, transformation, mean_pos_pc, source_color=None):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
    "    mesh_frame_2 = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.05, origin=mean_pos_pc)\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp, mesh_frame, mesh_frame_2])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #axis\n",
    "    source_mesh = o3d.io.read_triangle_mesh(\"../todel/apple.stl\")\n",
    "    target_mesh = o3d.io.read_triangle_mesh(\"../todel/apple.stl\")\n",
    "    source = source_mesh.sample_points_uniformly(number_of_points=5000)\n",
    "    # truncate source\n",
    "    # source = source.crop(source.get_axis_aligned_bounding_box())\n",
    "    source = o3d.geometry.PointCloud()\n",
    "    source.points = o3d.utility.Vector3dVector(pc)\n",
    "    source.colors = o3d.utility.Vector3dVector(pc_colors/255)\n",
    "    target = target_mesh.sample_points_uniformly(number_of_points=5000)\n",
    "    target_size = np.linalg.norm(target.get_max_bound() - target.get_min_bound())\n",
    "    source_size = np.linalg.norm(source.get_max_bound() - source.get_min_bound())\n",
    "    target.scale((1.3*source_size) / target_size, center=target.get_center())\n",
    "    threshold = 0.02\n",
    "    # trans_init = np.asarray([[0.862, 0.011, -0.507, -mean_pos_pc[0]],\n",
    "    #                          [-0.139, 0.967, -0.215, -mean_pos_pc[1]],\n",
    "    #                          [0.487, 0.255, 0.835,  -mean_pos_pc[2]], \n",
    "    #                          [0.0, 0.0, 0.0, 1.0]])\n",
    "    trans_init = np.asarray([[1.0, 0.0, 0.0, -mean_pos_pc[0]],\n",
    "                                [0.0, 1.0, 0.0, -mean_pos_pc[1]],\n",
    "                                [0.0, 0.0, 1.0,  -mean_pos_pc[2]],\n",
    "                                [0.0, 0.0, 0.0, 1.0]])\n",
    "    draw_registration_result(source, target, trans_init, mean_pos_pc, pc_colors/255)\n",
    "    print(\"Initial alignment\")\n",
    "    evaluation = o3d.pipelines.registration.evaluate_registration(source, target, threshold, trans_init)\n",
    "    print(evaluation)\n",
    "\n",
    "    # print(\"Apply point-to-point ICP\")\n",
    "    # reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    #     source, target, threshold, trans_init,\n",
    "    #     o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    # print(reg_p2p)\n",
    "    # print(\"Transformation is:\")\n",
    "    # print(reg_p2p.transformation)\n",
    "    # print(\"\")\n",
    "    # draw_registration_result(source, target, reg_p2p.transformation, mean_pos_pc)\n",
    "\n",
    "    print(\"Apply point-to-plane ICP\")\n",
    "    reg_p2l = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, trans_init,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "    print(reg_p2l)\n",
    "    print(\"Transformation is:\")\n",
    "    print(reg_p2l.transformation)\n",
    "    print(\"\")\n",
    "    draw_registration_result(source, target, reg_p2l.transformation,mean_pos_pc, pc_colors/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
