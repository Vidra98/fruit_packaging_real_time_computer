{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyLQR.sim import KDLRobot\n",
    "from PyLQR.system import PosOrnPlannerSys, PosOrnKeypoint\n",
    "from PyLQR.solver import BatchILQRCP, BatchILQR, ILQRRecursive\n",
    "from PyLQR.utils import primitives, PythonCallbackMessage\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D # <--- This is important for 3d plotting \n",
    "import cv2\n",
    "import matplotlib.cm as cm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from scipy.spatial.transform import Rotation \n",
    "\n",
    "from contact_grasp.srv import *\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "\n",
    "sys.path.append(\"/home/vdrame/catkin_ws/src/py_panda/PyPanda\")\n",
    "from PyPanda import Robot\n",
    "import rospy\n",
    "from PyPanda import Utils\n",
    "\n",
    "from utils.realsense_utils import RealCamera\n",
    "from utils.transform_utils import *\n",
    "from utils.iLQR_wrapper import iLQR\n",
    "import argparse\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "import time\n",
    "\n",
    "from sensor_msgs.msg import Image\n",
    "import rospy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_action(rbt, actions, control_freq, eef_pos=None, eef_quat=None, segmentation_type=None, show_agentview=False, object_range=[5,8]):\n",
    "    success = False\n",
    "    rate = rospy.Rate(int(control_freq))\n",
    "\n",
    "    for idx, action in tqdm(enumerate(actions)):\n",
    "        rbt.active_controller.send_command(action)\n",
    "        rate.sleep()\n",
    "        #env.sim.step()\n",
    "        if eef_pos is not None:\n",
    "            eef_pos.append(rbt.model.ee_pos_rel())\n",
    "        if eef_quat is not None:\n",
    "            eef_quat.append(rbt.model.ee_orn_rel())\n",
    "    success = True\n",
    "    return success, idx, eef_pos, eef_quat\n",
    "\n",
    "def generate_grasps_client(image, depth):\n",
    "    rospy.wait_for_service('generate_grasps')\n",
    "    try:\n",
    "        generate_grasps = rospy.ServiceProxy('generate_grasps', contactGraspnet)\n",
    "        resp1 = generate_grasps(image, depth)\n",
    "        return resp1.quat, resp1.pos, resp1.opening.data, resp1.detected.data\n",
    "    except rospy.ServiceException as e:\n",
    "        print(\"Service call failed: %s\"%e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PATH_TO_URDF = \"/home/vdrame/project/client/panda_description/urdf/panda_arm_robosuite.urdf\"\n",
    "# PATH_TO_URDF = \"/home/vdrame/Documents/ros_ws/src/rli_ws_base/py_panda/Tutorials/model.urdf\"\n",
    "\n",
    "# BASE_FRAME = \"panda_link0\"\n",
    "# TIP_FRAME = \"panda_tip\"\n",
    "# # TIP_FRAME = \"panda_grasptarget\"\n",
    "\n",
    "# # initial joint config\n",
    "# q0 = rbt.q\n",
    "# dq0 = [0]*rbt.dq\n",
    "\n",
    "# _qMax = np.array([2.87,   1.75,  2.8973, -0.05,  2.8973,  3.75,   2.8973])\n",
    "# _qMin = np.array([-2.87, -1.75, -2.8973, -3.05, -2.8973, -0.015, -2.8973])\n",
    "# # self._dqMax = np.array([2., 2., 2., 2., 2.6, 2.6, 2.6])\n",
    "# _dqMax = np.array([.5, .5, .5, .5, .6, .6, .6])\n",
    "\n",
    "# rbt_KDL = KDLRobot(PATH_TO_URDF, BASE_FRAME, TIP_FRAME, q0, dq0)\n",
    "# print(rbt_KDL.get_q())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load camera\n",
    "camera = RealCamera()\n",
    "camera.start()\n",
    "\n",
    "#retrieve image and depth\n",
    "for i in range(15):\n",
    "    rgb, depth_image, depth_scale = camera.get_rgb_depth()\n",
    "\n",
    "rgb, depth_image, depth_scale = camera.get_rgb_depth()\n",
    "# cv2.imwrite(\"img.png\", rgb)\n",
    "# cv2.imwrite(\"depth.png\", depth_image)\n",
    "# cv2.imwrite(\"depth_rescale.png\", depth_image*depth_scale)\n",
    "\n",
    "depth_scale = 0.001 # depth a publish under millimeter precision\n",
    "dispose_pos = np.array([0.1, 0.66, 0.1])\n",
    "dispose_orn_wxyz = np.array([0, 1, 0.35, 0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restart from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Connect to the robot\n",
    "rospy.init_node(\"python_node\",anonymous=True)\n",
    "rbt = Robot(\"panda\",use_gripper=True)\n",
    "\n",
    "print(\"rbt end effector pos:\", rbt.model.ee_pos_rel())\n",
    "print(\"rbt end effector quat (wxyz):\", rbt.model.ee_orn_rel())\n",
    "print(\"eef rot\",  Rotation.from_quat(convert_quat(rbt.model.ee_orn_rel(), to=\"xyzw\")).as_euler(\"xyz\", degrees=True))\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "ee_pose = np.eye(4)\n",
    "ee_pose[:3,:3] = quat2mat(convert_quat(rbt.model.ee_orn_rel(), to=\"xyzw\")) #xyzw\n",
    "ee_pose[:3,3] = rbt.model.ee_pos_rel() \n",
    "\n",
    "ee2hand = np.eye(4)\n",
    "ee2hand[2,3] = -0.1034\n",
    "\n",
    "hand2camera_pos = np.array([0.0488546636437146,-0.03384417860749521,0.0512776975002817]) \n",
    "hand2camera_quat = [0.012961267509189803,-0.0012768531849757236,0.7052247395136084,0.708864191484139] #xyzw \n",
    "hand2camera_mat = Rotation.from_quat(hand2camera_quat).as_matrix()\n",
    "\n",
    "hand2camera = np.eye(4)\n",
    "hand2camera[:3,:3] = hand2camera_mat\n",
    "hand2camera[:3,3] = hand2camera_pos\n",
    "\n",
    "camera_pose_world = ee_pose @ ee2hand @ hand2camera\n",
    "\n",
    "init_pos = rbt.model.ee_pos_rel()\n",
    "init_orn_wxyz = rbt.model.ee_orn_rel()\n",
    "\n",
    "# print(\"camera_pose_world :\", camera_pose_world)\n",
    "# # print(\"cam pose in world frame:\", Rotation.from_matrix(camera_pose_world[:3,:3]).as_euler(\"xyz\", degrees=True))\n",
    "# print(\"--------------------------------------------------------------------------\")\n",
    "rbt.gripper.homing()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grasping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eef_pos, eef_quat = [], []\n",
    "\n",
    "img_cv, depth_image, depth_scale = camera.get_rgb_depth()\n",
    "depth_cv = depth_image * depth_scale\n",
    "\n",
    "#Ros CV bridge to convert data from opencv to ROSImage\n",
    "bridge = CvBridge()\n",
    "\n",
    "# Call to the server\n",
    "orn, pos, opening, detected = generate_grasps_client(bridge.cv2_to_imgmsg(img_cv, \"bgr8\"), bridge.cv2_to_imgmsg(depth_cv, \"64FC1\"))\n",
    "# orn, pos = generate_grasps_client(img, depth)\n",
    "\n",
    "if detected:\n",
    "    grasps_pos_cam = np.array([pos.x, pos.y, pos.z])\n",
    "    # grasps_orn_cam_xyzw_raw = np.array([orn.x, orn.y, orn.z, orn.w])\n",
    "    grasps_orn_cam_xyzw_raw = Rotation.from_quat(np.array([orn.x, orn.y, orn.z, orn.w]))\n",
    "    rot = np.array([0., 0., 90])\n",
    "    grasp_rot_tmp = grasps_orn_cam_xyzw_raw.as_euler(\"XYZ\", degrees=True)\n",
    "    grasps_orn_eul = grasps_orn_cam_xyzw_raw.as_euler(\"XYZ\", degrees=True) + rot\n",
    "    grasps_orn_cam_xyzw = Rotation.from_euler(\"XYZ\", grasps_orn_eul, degrees=True).as_quat()\n",
    "    grasps_orn_cam_wxyz = convert_quat(grasps_orn_cam_xyzw, to=\"wxyz\")\n",
    "    grasps_mat_cam = quat2mat(grasps_orn_cam_xyzw)\n",
    "\n",
    "    grasp_pos_world = camera_pose_world[:3,:3] @ grasps_pos_cam + camera_pose_world[:3,3]\n",
    "    grasps_mat_world = camera_pose_world[:3,:3] @ grasps_mat_cam\n",
    "    grasps_orn_world_xyzw = mat2quat(grasps_mat_world)\n",
    "    grasp_orn_world_wxyz =  convert_quat(grasps_orn_world_xyzw, to=\"wxyz\")\n",
    "\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(\"grasps in camera frame :\\n pos :\", grasps_pos_cam, \"\\n grasps_orn_cam :\", grasps_orn_cam_xyzw, \"\\ngrasp world rot\",  Rotation.from_quat(grasps_orn_cam_xyzw).as_euler(\"xyz\", degrees=True))\n",
    "    print(\"\\n\\ngrasps in world frame :\\n pos :\", grasp_pos_world, \"\\n grasps_orn_world :\", grasps_orn_world_xyzw, \"\\ngrasp world rot\",  Rotation.from_quat(grasps_orn_world_xyzw).as_euler(\"xyz\", degrees=True))\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "else:\n",
    "    print(\"No grasping pose detection\")\n",
    "# cv2.imshow('rgb', rgb)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_grasps_cam = np.eye(4)\n",
    "pred_grasps_cam[:3,:3] = grasps_mat_world\n",
    "pred_grasps_cam[:3,3] = grasp_pos_world\n",
    "pred_grasps_cam = {1.0: np.array([pred_grasps_cam])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.switch_backend('QT5Agg')\n",
    "import mayavi.mlab as mlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualisation_utils import *\n",
    "cam_K = camera.getIntrinsic()[0]\n",
    "z_range = [0.2, 5]\n",
    "pc_full, pc_segments, pc_colors = extract_point_clouds(depth=depth_cv, K=cam_K, rgb=img_cv, z_range=z_range)\n",
    "\n",
    "for key in pred_grasps_cam:\n",
    "    pred_grasps_cam[key][:,:3,3] -= 0.1034 * pred_grasps_cam[key][:,:3,2]\n",
    "\n",
    "#show_image(self.rgb, self.segmap)\n",
    "visualize_grasps(pc_full, pred_grasps_cam, plot_opencv_cam=True, pc_colors=pc_colors, add_grasps=None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_gen = iLQR(rbt)\n",
    "grasp_jpos, grasp_x_pos, grasp_U, grasp_Ks, grasp_ds = traj_gen.grasping_trajectory(rbt.q, rbt.dq, grasp_pos_world, grasp_orn_world_wxyz, 120)\n",
    "\n",
    "grasp_q = grasp_jpos[-1]\n",
    "grasp_dq = np.zeros_like(grasp_q)\n",
    "dispose_jpos, dispose_x_pos, dispose_U, dispose_Ks, dispose_ds = traj_gen.dispose_trajectory(grasp_q, grasp_dq, grasp_pos_world, grasp_orn_world_wxyz, dispose_pos, dispose_orn_wxyz, 120)\n",
    "iLQR.plot_trajectory(init_pos, grasp_pos_world, grasp_x_pos, dispose_x_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbt.stop_controller()\n",
    "rbt.error_recovery()\n",
    "rbt.switch_controller(\"joint_velocity_controller\")\n",
    "rbt.active_controller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_U = np.array(grasp_U)\n",
    "success, idx, eef_pos, eef_quat = run_action(rbt, grasp_U[:80], 20)\n",
    "rbt.active_controller.send_command(np.zeros(7))\n",
    "time.sleep(1)\n",
    "success, idx, eef_pos, eef_quat = run_action(rbt, grasp_U[80:], 20)\n",
    "rbt.active_controller.send_command(np.zeros(7))\n",
    "rbt.gripper.move(width=opening-0.015)\n",
    "\n",
    "# print(\"rbt end effector pos:\", rbt.model.ee_pos_rel())\n",
    "# print(\"rbt end effector quat (wxyz):\", rbt.model.ee_orn_rel())\n",
    "# print(\"eef rot\",  Rotation.from_quat(rbt.model.ee_orn_rel()).as_euler(\"xyz\", degrees=True))\n",
    "# print(\"--------------------------------------------------------------------------\")\n",
    "# print(\"\\n\\ngrasps in world frame :\\n pos :\", grasp_pos_world, \"\\n grasps_orn_world :\", grasps_orn_world_xyzw, \"\\ngrasp world rot\",  Rotation.from_quat(grasps_orn_world_xyzw).as_euler(\"xyz\", degrees=True))\n",
    "# print(\"--------------------------------------------------------------------------\")\n",
    "# print(\"\\n\\ILQR final pose in world frame :\\n pos :\", grasp_x_pos[-1][:3], \"\\n grasps_orn_world wxyz:\", convert_quat(grasp_x_pos[-1][3:], to=\"xyzw\"), \"\\ngrasp world rot\",  Rotation.from_quat(convert_quat(grasp_x_pos[-1][3:], to=\"xyzw\")).as_euler(\"xyz\", degrees=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbt.gripper.move(width=opening-0.03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grasp_orn_world_wxyz)\n",
    "print(rbt.model.ee_orn_world())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispose_U = np.array(dispose_U)\n",
    "success, idx, eef_pos, eef_quat = run_action(rbt, dispose_U, 20)\n",
    "rbt.active_controller.send_command(np.zeros(7))\n",
    "rbt.gripper.move(width=0.07)\n",
    "rbt.gripper.homing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_jpos, return_x_pos, return_U, return_Ks, return_ds = traj_gen.grasping_trajectory(rbt.q, rbt.dq, init_pos, init_orn_wxyz, 120)\n",
    "return_U = np.array(return_U)\n",
    "success, idx, eef_pos, eef_quat = run_action(rbt, return_U, 20)\n",
    "rbt.active_controller.send_command(np.zeros(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"rbt end effector pos:\", rbt.model.ee_pos_rel())\n",
    "print(\"rbt end effector quat (wxyz):\", rbt.model.ee_orn_rel())\n",
    "print(\"eef rot\",  Rotation.from_quat(convert_quat(rbt.model.ee_orn_rel(), to=\"xyzw\")).as_euler(\"xyz\", degrees=True))\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print(init_pos)\n",
    "print(init_orn_wxyz)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"rbt end effector pos:\", rbt.model.ee_pos_rel())\n",
    "print(\"rbt end effector quat (wxyz):\", rbt.model.ee_orn_rel())\n",
    "print(\"eef rot\",  Rotation.from_quat(convert_quat(rbt.model.ee_orn_rel(), to=\"xyzw\")).as_euler(\"xyz\", degrees=True))\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print(\"dispose_pos : \", grasp_pos_world)\n",
    "print(\"dispose_orn :\", grasp_orn_world_wxyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbt.stop_controller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbt.gripper.grasp(force=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbt.gripper.move(width=0.07)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbt.gripper.homing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ros connexion to cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eef_pos, eef_quat = [], []\n",
    "\n",
    "# # rospy.init_node(\"python_node\",anonymous=True)\n",
    "# # img_cv, depth_image, depth_scale = camera.get_rgb_depth()\n",
    "# # depth_cv = depth_image * depth_scale\n",
    "\n",
    "# #Ros CV bridge to convert data from opencv to ROSImage\n",
    "# bridge = CvBridge()\n",
    "\n",
    "# depth = rospy.wait_for_message(\"/camera/aligned_depth_to_color/image_raw\", Image, timeout=2)\n",
    "# img = rospy.wait_for_message(\"/camera/color/image_raw\", Image, timeout=1)\n",
    "\n",
    "# img_cv = bridge.imgmsg_to_cv2(img, \"bgr8\")\n",
    "# depth_cv = bridge.imgmsg_to_cv2(depth, \"64FC1\")\n",
    "# if depth_cv.shape != img_cv.shape[:2]:\n",
    "#     img_cv = cv2.resize(img_cv, dsize=(depth_cv.shape[1], depth_cv.shape[0]), interpolation=cv2.INTER_AREA)\n",
    "# depth_cv = depth_cv * 0.001\n",
    "\n",
    "# # Call to the server\n",
    "# orn, pos = generate_grasps_client(bridge.cv2_to_imgmsg(img_cv, \"bgr8\"), bridge.cv2_to_imgmsg(depth_cv, \"64FC1\"))\n",
    "# # orn, pos = generate_grasps_client(img, depth)\n",
    "\n",
    "# grasps_pos_cam = np.array([pos.x, pos.y, pos.z])\n",
    "# grasps_orn_cam_xyzw = np.array([orn.x, orn.y, orn.z, orn.w])\n",
    "# grasps_orn_cam_wxyz = np.array([orn.w, orn.x, orn.y, orn.z])\n",
    "# grasps_mat_cam = quat2mat(grasps_orn_cam_xyzw)\n",
    "\n",
    "# grasp_pos_world = camera_pose_world[:3,:3] @ grasps_pos_cam + camera_pose_world[:3,3]\n",
    "# grasps_mat_world = camera_pose_world[:3,:3] @ grasps_mat_cam\n",
    "# grasps_orn_world_xyzw = mat2quat(grasps_mat_world)\n",
    "# grasp_orn_world_wxyz =  convert_quat(grasps_orn_world_xyzw, to=\"wxyz\")\n",
    "\n",
    "# print(\"--------------------------------------------------------------------------\")\n",
    "# print(\"grasps in camera frame :\\n pos :\", grasps_pos_cam, \"\\n grasps_orn_cam :\", grasps_orn_cam_xyzw, \"\\ngrasp world rot\",  Rotation.from_quat(grasps_orn_cam_xyzw).as_euler(\"xyz\", degrees=True))\n",
    "# print(\"\\n\\ngrasps in world frame :\\n pos :\", grasp_pos_world, \"\\n grasps_orn_world :\", grasps_orn_world_xyzw, \"\\ngrasp world rot\",  Rotation.from_quat(grasps_orn_world_xyzw).as_euler(\"xyz\", degrees=True))\n",
    "# print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "# # cv2.imshow('rgb', rgb)\n",
    "# # cv2.waitKey(0)\n",
    "# # cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
