{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyPanda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11770/2655374332.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/vdrame/catkin_ws/src/py_panda/PyPanda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPyPanda\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRobot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPyPanda\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUtils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PyPanda'"
     ]
    }
   ],
   "source": [
    "from PyLQR.sim import KDLRobot\n",
    "from PyLQR.system import PosOrnPlannerSys, PosOrnKeypoint\n",
    "from PyLQR.solver import BatchILQRCP, BatchILQR, ILQRRecursive\n",
    "from PyLQR.utils import primitives, PythonCallbackMessage\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from scipy.spatial.transform import Rotation \n",
    "\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "\n",
    "sys.path.append(\"/home/vdrame/catkin_ws/src/py_panda/PyPanda\")\n",
    "from PyPanda import Robot\n",
    "from PyPanda import Utils\n",
    "\n",
    "from utils.camera_utils import RealCamera, RealCameraROS\n",
    "from utils.transform_utils import *\n",
    "from utils.iLQR_wrapper import iLQR\n",
    "from utils.visualisation_utils import depth2pc\n",
    "from utils.ROS_utils import generate_grasps_client, format_pointcloud_msg, run_action, get_camera_pose, gridRegistrator\n",
    "\n",
    "import argparse\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "import time\n",
    "\n",
    "from contact_grasp.srv import contactGraspnetPointcloud2, contactGraspnetPointcloud2Response\n",
    "\n",
    "import json\n",
    "import rospy\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from sensor_msgs import point_cloud2\n",
    "from sensor_msgs.msg import PointField, CameraInfo, Image, PointCloud2\n",
    "from std_msgs.msg import Header\n",
    "from geometry_msgs.msg import PoseArray, Pose\n",
    "import message_filters\n",
    "\n",
    "import open3d as o3d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restart_controller(rbt, homing=False):\n",
    "    eef_pos, eef_quat = [], []\n",
    "    rbt.stop_controller()\n",
    "    rbt.error_recovery()\n",
    "    rbt.switch_controller(\"joint_velocity_controller\")\n",
    "    if homing:\n",
    "        rbt.gripper.homing()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge = CvBridge()\n",
    "try:\n",
    "    rospy.init_node(\"python_node\",anonymous=True)\n",
    "except:\n",
    "    print(\"rospy already initialized\")\n",
    "\n",
    "# dispose_pos = np.array([0.1, 0.66, 0.1])\n",
    "# dispose_orn_wxyz = np.array([0, 1, 0.35, 0])\n",
    "\n",
    "# Load robot\n",
    "rbt = Robot(\"panda\", use_gripper=True)\n",
    "traj_gen = iLQR(rbt)\n",
    "\n",
    "image_sub = message_filters.Subscriber(\"/grid_generator/disposability_grid\", Image)\n",
    "pose_sub = message_filters.Subscriber(\"/grid_generator/Posearray_pub\", PoseArray)\n",
    "ts = message_filters.TimeSynchronizer([pose_sub, image_sub], 1)\n",
    "grid = gridRegistrator(rbt)\n",
    "ts.registerCallback(grid.callback)\n",
    "\n",
    "camera_connexion = \"ROS\"\n",
    "if camera_connexion == \"ROS\":\n",
    "    camera = RealCameraROS()\n",
    "    intrinsic, distortion = camera.getIntrinsic()\n",
    "elif camera_connexion == \"pyWrapper\":\n",
    "    camera = RealCamera()\n",
    "    camera.start()\n",
    "    #retrieve image and depth to initialise camera, otherwise image is very dark\n",
    "    for i in range(15):\n",
    "        rgb, depth_image, depth_scale = camera.get_rgb_depth()\n",
    "else:\n",
    "    raise Exception(\"Please choose a valid camera connexion method: ROS or pyWrapper\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    restart_controller(rbt)\n",
    "    try:\n",
    "        result_msg = rospy.wait_for_message(\"/aruco_simple/result\", Image, timeout=1)\n",
    "    except rospy.ROSException:\n",
    "        print(\"Aruco topic not available\")\n",
    "        break\n",
    "    \n",
    "    result = bridge.imgmsg_to_cv2(result_msg, desired_encoding=\"passthrough\")\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow(\"result\", result)\n",
    "    cell_pos, cell_idx = grid.get_first_free_cell()\n",
    "\n",
    "    #load pos and orn from json file\n",
    "    with open('config/gridSearch_pos.json') as json_file:\n",
    "        gridSearch_views = json.load(json_file)\n",
    "\n",
    "    keys = gridSearch_views.keys()\n",
    "    for view_idx, key in enumerate(keys):\n",
    "        horizon = 30\n",
    "        view_jpos, view_x_pos, view_U, view_Ks, view_ds, pos_dif, orn_dif = traj_gen.direct_trajectory(rbt.q, rbt.dq, gridSearch_views[key][\"pos\"], gridSearch_views[key][\"orn_wxyz\"], horizon)\n",
    "        if pos_dif > 0.035:\n",
    "            print(\"Trajectory could not reach view continue to next view\")\n",
    "            continue\n",
    "        view_U = np.array(view_U)\n",
    "        success, idx, eef_pos, eef_quat = run_action(rbt, view_U, 20)\n",
    "        rbt.active_controller.send_command(np.zeros(7))\n",
    "        time.sleep(2.5)\n",
    "        cell_pos, cell_idx = grid.get_first_free_cell()\n",
    "        if cell_pos is not None:\n",
    "            break\n",
    "\n",
    "    if cell_pos is None:\n",
    "        print(\"No free cell\")\n",
    "    else:\n",
    "        # cell_pos = cell_pose.position\n",
    "        dispose_pos = cell_pos\n",
    "        dispose_orn_wxyz = np.array([0, 1, 0.35, 0])\n",
    "        try:\n",
    "            result_msg = rospy.wait_for_message(\"/grid_generator/result\", Image, timeout=1)\n",
    "            result = bridge.imgmsg_to_cv2(result_msg, desired_encoding=\"passthrough\")\n",
    "            result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            print(\"no grid generator image received\")\n",
    "        cv2.imshow(\"result\", result)\n",
    "        key = cv2.waitKey(0)\n",
    "        if key == ord(\"r\"):\n",
    "            continue\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "    key = cv2.waitKey(25)\n",
    "    if key == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grasping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pos and orn from json file\n",
    "with open('config/views_pos.json') as json_file:\n",
    "    views_pos = json.load(json_file)\n",
    "\n",
    "pos_dif = 1000\n",
    "keys = views_pos.keys()\n",
    "angle_range = [-140, 40]\n",
    "pc_fused = []\n",
    "pc_colors_fused = []\n",
    "reference_pose = np.eye(4)\n",
    "\n",
    "for view_idx, key in enumerate(keys):\n",
    "# while (not detected or not detected_with_collision):\n",
    "    horizon = 30\n",
    "    if abs(np.sum(np.array(rbt.model.ee_pos_rel()) - np.array(views_pos[key][\"pos\"]))) > 0.01:\n",
    "        view_jpos, view_x_pos, view_U, view_Ks, view_ds, pos_dif, orn_dif = traj_gen.direct_trajectory(rbt.q, rbt.dq, views_pos[key][\"pos\"], views_pos[key][\"orn_wxyz\"], horizon)\n",
    "\n",
    "        if pos_dif > 0.035:\n",
    "            print(\"Trajectory could not reach view continue to next view\")\n",
    "            continue\n",
    "\n",
    "        view_U = np.array(view_U)\n",
    "        success, idx, eef_pos, eef_quat = run_action(rbt, view_U, 20)\n",
    "        rbt.active_controller.send_command(np.zeros(7))\n",
    "        time.sleep(0.15)\n",
    "    else:\n",
    "        print( np.sum(np.array(rbt.model.ee_pos_rel()) - np.array(views_pos[key][\"pos\"])))\n",
    "        print(np.array(views_pos[key][\"pos\"]))\n",
    "        print(key)\n",
    "    \n",
    "    rbg_cv, depth_cv, depth_scale = camera.get_rgb_depth()\n",
    "    depth_cv = depth_cv * depth_scale\n",
    " \n",
    "    current_pose = get_camera_pose(rbt, ee_depth=-0.10340-0.005)\n",
    "\n",
    "    if view_idx == 0:\n",
    "        init_pos = rbt.model.ee_pos_rel()\n",
    "        init_orn_wxyz = rbt.model.ee_orn_rel()\n",
    "        reference_pose = get_camera_pose(rbt, ee_depth=-0.10340-0.005)\n",
    "        depth_init = depth_cv\n",
    "        rgb_init = rbg_cv\n",
    "        pc_fused, pc_colors_fused = depth2pc(depth_init, intrinsic, rgb_init)\n",
    "        pc_fused, pc_colors_fused = regularize_pc(pc_fused, pc_colors_fused, \n",
    "                                                  downsampling_method=\"voxel\", voxel_size=0.005,\n",
    "                                                  outlier_filtering_method=\"radius\", radius_param_arg=[25, 0.015])\n",
    "    else:\n",
    "        pc_fused, pc_colors_fused = add_view2pc(pc_fused, pc_colors_fused, reference_pose, current_pose, new_gbr=rbg_cv, \n",
    "                                                new_depth=depth_cv, cam_intrisic=intrinsic, regularize=True, voxel_size=0.005)\n",
    "    pc2_msg = format_pointcloud_msg(pc_fused, pc_colors_fused)\n",
    "    bgr = cv2.cvtColor(rgb_init, cv2.COLOR_RGB2BGR)\n",
    "    bgr_msg = bridge.cv2_to_imgmsg(rgb_init, encoding=\"bgr8\")\n",
    "\n",
    "    orn, pos, opening, score, detected, detected_with_collision = generate_grasps_client(pc2_msg, bgr_msg)\n",
    "\n",
    "    if (detected or detected_with_collision) and opening > 0.03:\n",
    "        grasp_pos_world, grasps_orn_world_xyzw = poseCam2World(pos, orn, reference_pose)      \n",
    "        grasps_orn_world_xyzw = correct_angle(grasps_orn_world_xyzw, angle_range)\n",
    "        grasp_orn_world_wxyz = convert_quat(grasps_orn_world_xyzw, to=\"wxyz\")\n",
    "        print(\"--------------------------------------------------------------------------\")\n",
    "        print(\"\\n\\ngrasps in world frame :\\n pos :\", grasp_pos_world, \"\\n grasps_orn_world :\", grasps_orn_world_xyzw, \"\\ngrasp world rot\",  Rotation.from_quat(grasps_orn_world_xyzw).as_euler(\"XYZ\", degrees=True))\n",
    "        print(\"------------------------------------ --------------------------------------\")\n",
    "        break\n",
    "\n",
    "\n",
    "# trajectory\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "cell_pos, cell_idx = grid.get_first_free_cell()\n",
    "if cell_pos is None:\n",
    "    print(\"No free cell\")\n",
    "else:\n",
    "    # cell_pos = cell_pose.position\n",
    "    print(grid.get_disposability_grid())\n",
    "    dispose_pos = cell_pos + np.array([0., 0., 0.015])\n",
    "    dispose_orn_wxyz = np.array([0, 1, 0.35, 0])\n",
    "\n",
    "\n",
    "grasp_horizon = 60\n",
    "dispose_horizon = 60\n",
    "grasp_jpos, grasp_x_pos, grasp_U, grasp_Ks, grasp_ds, pos_dif, orn_dif = traj_gen.grasping_trajectory(rbt.q, rbt.dq, grasp_pos_world, grasp_orn_world_wxyz, grasp_horizon)\n",
    "pos_threshold = 0.015\n",
    "if pos_dif > pos_threshold:\n",
    "    print(\"grasp trajectory error please change viewpose\")\n",
    "grasp_q = grasp_jpos[-1]\n",
    "grasp_dq = np.zeros_like(grasp_q)\n",
    "dispose_jpos, dispose_x_pos, dispose_U, dispose_Ks, dispose_ds, pos_dif, orn_dif = traj_gen.dispose_trajectory(grasp_q, grasp_dq, grasp_pos_world, grasp_orn_world_wxyz, dispose_pos, dispose_orn_wxyz, dispose_horizon)\n",
    "iLQR.plot_trajectory(init_pos, grasp_pos_world, grasp_x_pos, dispose_x_pos)\n",
    "\n",
    "\n",
    "# Move to the grasp pose\n",
    "if opening + 0.01 <= 0.08:\n",
    "    rbt.gripper.move(width=opening + 0.01)\n",
    "else:\n",
    "    rbt.gripper.move(width=0.08)\n",
    "\n",
    "# Grasp the object\n",
    "grasp_U = np.array(grasp_U)\n",
    "success, idx, eef_pos, eef_quat = run_action(rbt, grasp_U[:-30], 20)\n",
    "rbt.active_controller.send_command(np.zeros(7))\n",
    "time.sleep(1)\n",
    "success, idx, eef_pos, eef_quat = run_action(rbt, grasp_U[-30:], 20)\n",
    "rbt.active_controller.send_command(np.zeros(7))\n",
    "rbt.gripper.move(width=opening-0.02)\n",
    "\n",
    "\n",
    "\n",
    "# Dispose the object\n",
    "dispose_U = np.array(dispose_U)\n",
    "success, idx, eef_pos, eef_quat = run_action(rbt, dispose_U, 20)\n",
    "rbt.active_controller.send_command(np.zeros(7))\n",
    "rbt.gripper.stop()\n",
    "rbt.gripper.move(width=0.082)\n",
    "\n",
    "# Register the object in the grid\n",
    "grid.set_cell_occupancy(cell_idx, 0)\n",
    "\n",
    "\n",
    "return_horizon = 45\n",
    "return_jpos, return_x_pos, return_U, return_Ks, return_ds, pos_dif, orn_dif = traj_gen.return_trajectory(rbt.q, rbt.dq, dispose_pos, dispose_orn_wxyz, init_pos, init_orn_wxyz, return_horizon)\n",
    "return_U = np.array(return_U)\n",
    "success, idx, eef_pos, eef_quat = run_action(rbt, return_U, 20)\n",
    "rbt.active_controller.send_command(np.zeros(7))\n",
    "\n",
    "if rbt.error:\n",
    "    print(\"robot encountered error\")\n",
    "    restart_controller(rbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argwhere(np.sum(grasp_U, axis=1)<0.0001))\n",
    "grasp_U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restart_controller(rbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restart_controller(rbt)\n",
    "rbt.gripper.move(width=opening-0.015)\n",
    "\n",
    "\n",
    "\n",
    "# Dispose the object\n",
    "dispose_U = np.array(dispose_U)\n",
    "success, idx, eef_pos, eef_quat = run_action(rbt, dispose_U, 20)\n",
    "rbt.active_controller.send_command(np.zeros(7))\n",
    "rbt.gripper.stop()\n",
    "rbt.gripper.move(width=0.082)\n",
    "\n",
    "# Register the object in the grid\n",
    "grid.set_cell_occupancy(cell_idx, 0)\n",
    "\n",
    "\n",
    "return_horizon = 45\n",
    "return_jpos, return_x_pos, return_U, return_Ks, return_ds, pos_dif, orn_dif = traj_gen.return_trajectory(rbt.q, rbt.dq, dispose_pos, dispose_orn_wxyz, init_pos, init_orn_wxyz, return_horizon)\n",
    "return_U = np.array(return_U)\n",
    "success, idx, eef_pos, eef_quat = run_action(rbt, return_U, 20)\n",
    "rbt.active_controller.send_command(np.zeros(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbt.stop_controller()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
