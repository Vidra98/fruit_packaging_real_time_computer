{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2023-06-21 15:06:37,824 - utils - NumExpr defaulting to 8 threads.\n",
      "INFO - 2023-06-21 15:06:38,376 - base_toolkit - Could not load plugin 'qt' from 'pyface.ui.qt.init'\n",
      "INFO - 2023-06-21 15:06:38,377 - base_toolkit - No pyface.toolkits plugin could be loaded for qt\n",
      "INFO - 2023-06-21 15:06:38,377 - base_toolkit - Could not load traitsui.toolkits plugin 'qt' from 'traitsui.qt4'\n",
      "INFO - 2023-06-21 15:06:38,378 - base_toolkit - Could not load traitsui.toolkits plugin 'wx' from 'traitsui.wx'\n",
      "INFO - 2023-06-21 15:06:38,490 - base_toolkit - Could not load plugin 'qt4' from 'pyface.ui.qt.init'\n",
      "INFO - 2023-06-21 15:06:38,492 - base_toolkit - No pyface.toolkits plugin could be loaded for qt4\n",
      "INFO - 2023-06-21 15:06:38,492 - base_toolkit - Could not load traitsui.toolkits plugin 'qt4' from 'traitsui.qt4'\n"
     ]
    }
   ],
   "source": [
    "from PyLQR.sim import KDLRobot\n",
    "from PyLQR.system import PosOrnPlannerSys, PosOrnKeypoint\n",
    "from PyLQR.solver import BatchILQRCP, BatchILQR, ILQRRecursive\n",
    "from PyLQR.utils import primitives, PythonCallbackMessage\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from scipy.spatial.transform import Rotation \n",
    "\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "\n",
    "sys.path.append(\"/home/vdrame/catkin_ws/src/py_panda/PyPanda\")\n",
    "from PyPanda import Robot\n",
    "from PyPanda import Utils\n",
    "\n",
    "from utils.camera_utils import RealCamera, RealCameraROS\n",
    "from utils.transform_utils import *\n",
    "from utils.iLQR_wrapper import iLQR\n",
    "from utils.visualisation_utils import depth2pc\n",
    "from utils.ROS_utils import generate_grasps_client, format_pointcloud_msg, run_action, get_camera_pose, gridRegistrator\n",
    "\n",
    "import argparse\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "import time\n",
    "\n",
    "from contact_grasp.srv import contactGraspnetPointcloud2, contactGraspnetPointcloud2Response\n",
    "\n",
    "import json\n",
    "import rospy\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from sensor_msgs import point_cloud2\n",
    "from sensor_msgs.msg import PointField, CameraInfo, Image, PointCloud2\n",
    "from std_msgs.msg import Header\n",
    "from geometry_msgs.msg import PoseArray, Pose\n",
    "import message_filters\n",
    "\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restart_controller(rbt, homing=False):\n",
    "    eef_pos, eef_quat = [], []\n",
    "    rbt.stop_controller()\n",
    "    rbt.error_recovery()\n",
    "    rbt.switch_controller(\"joint_velocity_controller\")\n",
    "    if homing:\n",
    "        rbt.gripper.homing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference between iLQR model ee and real robot ee\n",
      "quat (zyzw) :[ 4.2164770e-06 -1.1110131e-07 -1.2038387e-06  1.0000000e+00]\n",
      "pos:[ 3.28867958e-07 -6.94548414e-07  3.99218198e-07]\n",
      "Camera topic found\n"
     ]
    }
   ],
   "source": [
    "bridge = CvBridge()\n",
    "try:\n",
    "    rospy.init_node(\"python_node\",anonymous=True)\n",
    "except:\n",
    "    print(\"rospy already initialized\")\n",
    "\n",
    "# dispose_pos = np.array([dim, 0.66, 0.1])\n",
    "# dispose_orn_wxyz = np.array([0, 1, 0.35, 0])\n",
    "\n",
    "# Load robot\n",
    "rbt = Robot(\"panda\", use_gripper=True)\n",
    "traj_gen = iLQR(rbt)\n",
    "\n",
    "image_sub = message_filters.Subscriber(\"/grid_generator/disposability_grid\", Image)\n",
    "pose_sub = message_filters.Subscriber(\"/grid_generator/Posearray_pub\", PoseArray)\n",
    "ts = message_filters.TimeSynchronizer([pose_sub, image_sub], 1)\n",
    "grid = gridRegistrator(rbt)\n",
    "ts.registerCallback(grid.callback)\n",
    "\n",
    "camera_connexion = \"ROS\"\n",
    "if camera_connexion == \"ROS\":\n",
    "    camera = RealCameraROS()\n",
    "    intrinsic, distortion = camera.getIntrinsic()\n",
    "elif camera_connexion == \"pyWrapper\":\n",
    "    camera = RealCamera()\n",
    "    camera.start()\n",
    "    #retrieve image and depth to initialise camera, otherwise image is very dark\n",
    "    for i in range(15):\n",
    "        rgb, depth_image, depth_scale = camera.get_rgb_depth()\n",
    "else:\n",
    "    raise Exception(\"Please choose a valid camera connexion method: ROS or pyWrapper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] [1687352805.642083]: No controllers are running\n"
     ]
    }
   ],
   "source": [
    "restart_controller(rbt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_triangle(dim=0.1, color=[1, 0, 0]):\n",
    "    halfdim=dim/2\n",
    "    points = [\n",
    "        [0, 0, 0],\n",
    "        [-halfdim, -halfdim, dim],\n",
    "        [halfdim, -halfdim, dim],\n",
    "        [halfdim, halfdim, dim],\n",
    "        [-halfdim, halfdim, dim],\n",
    "\n",
    "    ]\n",
    "    lines = [\n",
    "        [0, 1],\n",
    "        [0, 2],\n",
    "        [0, 3],\n",
    "        [0, 4],\n",
    "        [1, 2],\n",
    "        [2, 3],\n",
    "        [3, 4],\n",
    "        [4, 1],\n",
    "\n",
    "    ]\n",
    "    colors = [color for i in range(len(lines))]\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(points),\n",
    "        lines=o3d.utility.Vector2iVector(lines),\n",
    "    )\n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    return line_set\n",
    "\n",
    "ls = draw_triangle()\n",
    "o3d.visualization.draw_geometries([ls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling time: 0.8010735511779785s, Filtering time: 0.030261754989624023s\n",
      "[TriangleMesh with 1134 points and 2240 triangles., LineSet with 8 lines.]\n",
      "Downsampling time: 0.10647106170654297s, Filtering time: 0.11161684989929199s\n",
      "[TriangleMesh with 1134 points and 2240 triangles., LineSet with 8 lines., TriangleMesh with 1134 points and 2240 triangles., LineSet with 8 lines.]\n",
      "Downsampling time: 0.22248148918151855s, Filtering time: 0.12884736061096191s\n",
      "[TriangleMesh with 1134 points and 2240 triangles., LineSet with 8 lines., TriangleMesh with 1134 points and 2240 triangles., LineSet with 8 lines., TriangleMesh with 1134 points and 2240 triangles., LineSet with 8 lines.]\n"
     ]
    }
   ],
   "source": [
    "#load pos and orn from json file\n",
    "with open('config/views_pos.json') as json_file:\n",
    "    views_pos = json.load(json_file)\n",
    "\n",
    "pos_dif = 1000\n",
    "keys = views_pos.keys()\n",
    "angle_range = [-140, 40]\n",
    "pc_fused = []\n",
    "pc_colors_fused = []\n",
    "reference_pose = np.eye(4)\n",
    "plot_coordinate = []\n",
    "for view_idx, key in enumerate(keys):\n",
    "# while (not detected or not detected_with_collision):\n",
    "    horizon = 30\n",
    "    if abs(np.sum(np.array(rbt.model.ee_pos_rel()) - np.array(views_pos[key][\"pos\"]))) > 0.01:\n",
    "        view_jpos, view_x_pos, view_U, view_Ks, view_ds, pos_dif, orn_dif = traj_gen.direct_trajectory(rbt.q, rbt.dq, views_pos[key][\"pos\"], views_pos[key][\"orn_wxyz\"], horizon)\n",
    "\n",
    "        if pos_dif > 0.035:\n",
    "            print(\"Trajectory could not reach view continue to next view\")\n",
    "            continue\n",
    "\n",
    "        view_U = np.array(view_U)\n",
    "        success, idx, eef_pos, eef_quat = run_action(rbt, view_U, 20)\n",
    "        rbt.active_controller.send_command(np.zeros(7))\n",
    "        time.sleep(0.15)\n",
    "    else:\n",
    "        print( np.sum(np.array(rbt.model.ee_pos_rel()) - np.array(views_pos[key][\"pos\"])))\n",
    "        print(np.array(views_pos[key][\"pos\"]))\n",
    "        print(key)\n",
    "    \n",
    "    rbg_cv, depth_cv, depth_scale = camera.get_rgb_depth()\n",
    "    depth_cv = depth_cv * depth_scale\n",
    " \n",
    "    current_pose = get_camera_pose(rbt, ee_depth=-0.10340-0.005)\n",
    "\n",
    "    if view_idx == 0:\n",
    "        init_pos = rbt.model.ee_pos_rel()\n",
    "        init_orn_wxyz = rbt.model.ee_orn_rel()\n",
    "        reference_pose = get_camera_pose(rbt, ee_depth=-0.10340-0.005)\n",
    "        depth_init = depth_cv\n",
    "        rgb_init = rbg_cv\n",
    "        pc_fused, pc_colors_fused = depth2pc(depth_init, intrinsic, rgb_init)\n",
    "        pc_fused, pc_colors_fused = regularize_pc(pc_fused, pc_colors_fused, \n",
    "                                                  downsampling_method=\"voxel\", voxel_size=0.005,\n",
    "                                                  outlier_filtering_method=\"radius\", radius_param_arg=[25, 0.015])\n",
    "    else:\n",
    "        pc_fused, pc_colors_fused = add_view2pc(pc_fused, pc_colors_fused, reference_pose, current_pose, new_gbr=rbg_cv, \n",
    "                                                new_depth=depth_cv, cam_intrisic=intrinsic, regularize=True, voxel_size=0.005)\n",
    "\n",
    "    coordinate = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1)\n",
    "    coordinate_line = draw_triangle(color=[1,0,0])\n",
    "\n",
    "    coordinate_line.transform(current_pose)\n",
    "    coordinate.transform(current_pose)\n",
    "    plot_coordinate.append(coordinate)\n",
    "    plot_coordinate.append(coordinate_line)\n",
    "\n",
    "    print(plot_coordinate)\n",
    "    pc_o3d = o3d.geometry.PointCloud()\n",
    "    pc_o3d.points = o3d.utility.Vector3dVector(pc_fused)\n",
    "    pc_o3d.colors = o3d.utility.Vector3dVector(pc_colors_fused/255)\n",
    "    coordinate = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1)\n",
    "    # coordinate.translate([0,0 , 0.4])\n",
    "    pc_o3d.transform(reference_pose)\n",
    "    to_draw = plot_coordinate.copy()\n",
    "    to_draw.append(pc_o3d)\n",
    "    o3d.visualization.draw_geometries(to_draw)\n",
    "    if view_idx == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36209141, -0.80969669,  0.46182365,  0.03713801],\n",
       "       [-0.29578505, -0.56964332, -0.76682314,  0.59482619],\n",
       "       [ 0.88396893,  0.14105952, -0.44575912,  0.16624133],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.89981344, -2.09495538,  0.60591773],\n",
       "       [ 0.89961087, -2.09741915,  0.60321609],\n",
       "       [ 0.88341283, -2.1139854 ,  0.53865819],\n",
       "       ...,\n",
       "       [ 1.21074279, -1.82221269,  0.51719078],\n",
       "       [ 0.0747867 ,  0.40400081, -0.01162093],\n",
       "       [ 0.10828803,  0.3671978 ,  0.05573272]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(pc_o3d.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
